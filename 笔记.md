# d2l学习笔记
## 第五章 卷积神经网络
### 为什么选择卷积层
首先，多层感知机的输入是二维图像X，其隐藏表示H在数学上是一个矩阵，在代码中表示为二维张量。其中X和
H具有相同的形状。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构
使用X,和H分别表示输入图像和隐藏表示中位置（i,j）处的像素。为了使每个隐藏神经元都能接收到每个输
入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量W。假设
U包含偏置参数，我们可以将全连接层形式化地表示为
$$
\begin{array}{l}{{[{\bf\cal H}]_{i,j}=[{\bf U}]_{i,j}+\sum_{k}\sum_{l}[\mathsf{W}]_{i,j,k,l}[{\bf X}]_{k,l}}}\\ {{=[{\bf U}]_{i,j}+\sum_{a}\sum_{b}[\mathsf{V}]_{i,j,}=[\mathsf{U}]_{i,j+}.}}\end{array} 
$$
(6.1.1)
其中，从W到V的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。我们只需重新
索引下标(.,),使k=i+a、 $l=j+b,$ 由此可得VI $i,j,a,b\overline{{{\Big(}}}\sqrt{\Big|}_{i,j,i+a,j+b\circ}$ 索引|α和b通过在正偏移和负偏移
之间移动覆盖了整个图像。对于隐藏表示中任意给定位置（i,j）处的像素值Hi,，可以通过在α中以(,))为中心
对像素进行加权求和得到，加权使用的权重为DMi,o,be