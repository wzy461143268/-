{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torchvision.datasets.FashionMNIST(root='./data',train=True,download=True,transform=torchvision.transforms.ToTensor())\n",
    "train_data,test_data=train_test_split(data,test_size=0.2,random_state=42)\n",
    "train_set=torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_set=torch.utils.data.DataLoader(test_data,batch_size=64,shuffle=True)\n",
    "del data,train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet=nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "        nn.Linear(120, 84), nn.Sigmoid(),\n",
    "        nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): Sigmoid()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): Sigmoid()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (8): Sigmoid()\n",
       "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (10): Sigmoid()\n",
       "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight) # 使用Xavier均匀分布初始化权重\n",
    "\n",
    "LeNet.apply(init_weights) # 初始化权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net,device=None):\n",
    "    if device is None and isinstance(net,torch.nn.Module):\n",
    "        device=list(net.parameters())[0].device\n",
    "    acc_sum,n=0.0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_iter:\n",
    "            if isinstance(net,torch.nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum+=(net(X.to(device)).argmax(dim=1)==y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else:\n",
    "                if('is_training' in net.__code__.co_varnames):\n",
    "                    acc_sum+=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "            n+=y.shape[0]\n",
    "    return acc_sum/n\n",
    "\n",
    "def train(net,train_iter,test_iter,loss,epochs,lr,device):\n",
    "    net=net.to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss,train_acc,n=0.0,0.0,0\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=l.cpu().item()\n",
    "            train_acc+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'%(epoch+1,train_loss/n,train_acc/n,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0192, train acc 0.551, test acc 0.721\n",
      "epoch 2, loss 0.0107, train acc 0.737, test acc 0.756\n",
      "epoch 3, loss 0.0094, train acc 0.768, test acc 0.785\n",
      "epoch 4, loss 0.0084, train acc 0.794, test acc 0.809\n",
      "epoch 5, loss 0.0077, train acc 0.815, test acc 0.822\n",
      "epoch 6, loss 0.0072, train acc 0.830, test acc 0.827\n",
      "epoch 7, loss 0.0068, train acc 0.839, test acc 0.844\n",
      "epoch 8, loss 0.0065, train acc 0.845, test acc 0.846\n",
      "epoch 9, loss 0.0063, train acc 0.853, test acc 0.850\n",
      "epoch 10, loss 0.0061, train acc 0.857, test acc 0.853\n"
     ]
    }
   ],
   "source": [
    "train(LeNet,train_set,test_set,torch.nn.CrossEntropyLoss(),10,0.001,torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): Sigmoid()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): Sigmoid()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (8): Sigmoid()\n",
       "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (10): Sigmoid()\n",
       "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1765,  0.6679,  0.7620,  0.1233, -0.3778],\n",
      "          [-0.4203,  0.9429,  0.9815,  0.1715, -0.4026],\n",
      "          [-0.5020,  0.9010,  1.1045, -0.1239, -0.7185],\n",
      "          [-0.6585,  0.7684,  0.9329, -0.1525, -0.9039],\n",
      "          [-0.5508,  0.6134,  0.6255, -0.1812, -1.1147]]],\n",
      "\n",
      "\n",
      "        [[[-0.7014,  0.1782,  0.5097, -0.1563, -0.4662],\n",
      "          [-0.2249,  1.2198,  1.4461,  0.0456, -0.7614],\n",
      "          [-0.3935,  1.4770,  1.8339,  0.3682, -0.4790],\n",
      "          [-0.8663,  0.5880,  1.0173, -0.0251, -0.7535],\n",
      "          [-0.9659,  0.3668,  0.5634,  0.0945, -0.8074]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1466,  0.3485,  0.2595,  0.5414, -0.0305],\n",
      "          [ 0.9193,  2.4310,  2.3361,  1.2598,  0.2747],\n",
      "          [ 0.7885,  2.7417,  2.8556,  1.3662,  0.2222],\n",
      "          [ 0.1595,  1.4333,  1.9664,  0.9787, -0.0576],\n",
      "          [-0.6857,  0.1164,  0.5180,  0.1032, -0.0194]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0046, -0.4949, -0.5754, -0.1067,  0.2487],\n",
      "          [ 0.1352, -0.4158, -0.5282, -0.2789,  0.3486],\n",
      "          [-0.0577, -0.5471, -0.3966, -0.3397,  0.1028],\n",
      "          [ 0.1536, -0.1973, -0.4498,  0.0731,  0.3381],\n",
      "          [ 0.3961, -0.2083, -0.1588,  0.2124,  0.6097]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4230, -0.1583, -0.6377,  0.0684,  0.3718],\n",
      "          [-0.1679, -0.9641, -2.7424, -1.9986, -0.1219],\n",
      "          [ 0.3516, -1.1406, -2.8345, -2.1905, -0.3384],\n",
      "          [ 0.5671,  0.1119, -0.8096, -1.1195,  0.0769],\n",
      "          [ 0.8358,  0.4521,  0.0875, -0.2881,  0.4777]]],\n",
      "\n",
      "\n",
      "        [[[-0.3481,  0.7368,  0.4871, -0.2802, -0.6841],\n",
      "          [-0.3028,  0.9288,  0.9792,  0.0794, -0.6003],\n",
      "          [-0.3896,  0.8372,  1.0683,  0.0110, -0.6483],\n",
      "          [-0.2600,  0.8025,  0.9303,  0.0927, -0.7316],\n",
      "          [-0.5173,  0.5275,  0.3756, -0.1787, -1.0949]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(LeNet[0].weight.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
