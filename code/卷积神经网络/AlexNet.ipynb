{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0654,  0.0340, -0.0612,  ..., -0.0685, -0.0366, -0.0206],\n",
      "          [ 0.0784,  0.0252, -0.0367,  ..., -0.0175,  0.0799, -0.0486],\n",
      "          [ 0.0828, -0.0273,  0.0200,  ...,  0.0648, -0.0418, -0.0337],\n",
      "          ...,\n",
      "          [ 0.0197,  0.0816,  0.0731,  ..., -0.0684,  0.0304,  0.0072],\n",
      "          [ 0.0612,  0.0586,  0.0725,  ...,  0.0287, -0.0501, -0.0778],\n",
      "          [-0.0109, -0.0448,  0.0840,  ...,  0.0741,  0.0030,  0.0640]]],\n",
      "\n",
      "\n",
      "        [[[-0.0235,  0.0482,  0.0226,  ..., -0.0747,  0.0404, -0.0451],\n",
      "          [-0.0811, -0.0094, -0.0669,  ..., -0.0782,  0.0318,  0.0106],\n",
      "          [ 0.0242,  0.0182,  0.0183,  ..., -0.0873, -0.0791, -0.0480],\n",
      "          ...,\n",
      "          [-0.0236,  0.0170,  0.0383,  ..., -0.0126,  0.0444, -0.0060],\n",
      "          [ 0.0419, -0.0756, -0.0603,  ...,  0.0063, -0.0574,  0.0431],\n",
      "          [ 0.0889, -0.0080,  0.0079,  ...,  0.0259,  0.0384, -0.0163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0088, -0.0491, -0.0414,  ...,  0.0761,  0.0494,  0.0578],\n",
      "          [-0.0437,  0.0798,  0.0313,  ...,  0.0627,  0.0263, -0.0452],\n",
      "          [ 0.0166, -0.0874,  0.0141,  ...,  0.0752, -0.0882, -0.0428],\n",
      "          ...,\n",
      "          [ 0.0816,  0.0639, -0.0838,  ...,  0.0077,  0.0171,  0.0712],\n",
      "          [ 0.0668,  0.0757,  0.0839,  ...,  0.0222,  0.0368,  0.0874],\n",
      "          [-0.0640,  0.0868,  0.0210,  ..., -0.0480, -0.0403, -0.0367]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0212,  0.0586,  0.0050,  ..., -0.0785, -0.0429,  0.0847],\n",
      "          [-0.0021,  0.0895, -0.0227,  ...,  0.0850, -0.0301,  0.0519],\n",
      "          [ 0.0799,  0.0150,  0.0827,  ..., -0.0539, -0.0717, -0.0801],\n",
      "          ...,\n",
      "          [-0.0420, -0.0582, -0.0509,  ..., -0.0015, -0.0637, -0.0460],\n",
      "          [ 0.0539,  0.0075,  0.0017,  ..., -0.0244, -0.0049, -0.0479],\n",
      "          [-0.0841,  0.0582, -0.0483,  ...,  0.0247, -0.0135, -0.0737]]],\n",
      "\n",
      "\n",
      "        [[[-0.0284, -0.0647,  0.0539,  ...,  0.0225, -0.0833,  0.0315],\n",
      "          [ 0.0137, -0.0825, -0.0130,  ...,  0.0458,  0.0564, -0.0599],\n",
      "          [-0.0221,  0.0242, -0.0851,  ...,  0.0337, -0.0170, -0.0387],\n",
      "          ...,\n",
      "          [-0.0504,  0.0675,  0.0369,  ...,  0.0466, -0.0816, -0.0110],\n",
      "          [-0.0104,  0.0293, -0.0083,  ..., -0.0735, -0.0081,  0.0900],\n",
      "          [ 0.0385,  0.0163,  0.0257,  ...,  0.0088, -0.0729, -0.0596]]],\n",
      "\n",
      "\n",
      "        [[[-0.0418, -0.0739,  0.0176,  ...,  0.0494,  0.0649, -0.0245],\n",
      "          [ 0.0641,  0.0725,  0.0007,  ..., -0.0379, -0.0782,  0.0672],\n",
      "          [ 0.0255,  0.0587, -0.0771,  ..., -0.0280, -0.0552,  0.0027],\n",
      "          ...,\n",
      "          [ 0.0024, -0.0124,  0.0146,  ..., -0.0069, -0.0573,  0.0780],\n",
      "          [ 0.0347,  0.0813,  0.0406,  ...,  0.0105,  0.0879,  0.0296],\n",
      "          [-0.0534,  0.0411,  0.0592,  ..., -0.0615, -0.0342, -0.0296]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
      "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
      "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 6400])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.normal(0, 1, (1,3, 224, 224))\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
